# SARIF Parser

–ü–∞—Ä—Å–µ—Ä –¥–ª—è –æ—Ç—á–µ—Ç–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ SARIF 2.1.0 (Static Analysis Results Interchange Format).

## üìã –û–ø–∏—Å–∞–Ω–∏–µ

SARIF Parser - —ç—Ç–æ Python –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –∏ –∞–Ω–∞–ª–∏–∑–∞ –æ—Ç—á–µ—Ç–æ–≤ –æ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ SARIF. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –æ—Ç—á–µ—Ç—ã –æ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–¥–∞.

### –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã

- ‚úÖ PT BlackBox (Positive Technologies)
- ‚úÖ PT Application Inspector (Positive Technologies)
- ‚úÖ –õ—é–±—ã–µ –¥—Ä—É–≥–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç SARIF 2.1.0

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### –£—Å—Ç–∞–Ω–æ–≤–∫–∞

–ü–∞—Ä—Å–µ—Ä –Ω–µ —Ç—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–æ–ª—å–∫–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é –±–∏–±–ª–∏–æ—Ç–µ–∫—É Python.

```bash
# –°–∫–æ–ø–∏—Ä—É–π—Ç–µ —Ñ–∞–π–ª sarif_parser.py –≤ –≤–∞—à –ø—Ä–æ–µ–∫—Ç
```

### –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

```python
from sarif_parser import SarifParser, print_report_summary

# –ü–∞—Ä—Å–∏–Ω–≥ SARIF —Ñ–∞–π–ª–∞
report = SarifParser.parse_file("report.sarif")

# –í—ã–≤–æ–¥ –∫—Ä–∞—Ç–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
print_report_summary(report)

# –î–æ—Å—Ç—É–ø –∫ –¥–∞–Ω–Ω—ã–º
print(f"–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç: {report.tool.name}")
print(f"–í—Å–µ–≥–æ –Ω–∞—Ö–æ–¥–æ–∫: {len(report.findings)}")
print(f"–í—Å–µ–≥–æ –ø—Ä–∞–≤–∏–ª: {len(report.rules)}")
```

## üìä –û—Å–Ω–æ–≤–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

### 1. –ü–∞—Ä—Å–∏–Ω–≥ SARIF —Ñ–∞–π–ª–æ–≤

```python
from sarif_parser import SarifParser

# –ò–∑ —Ñ–∞–π–ª–∞
report = SarifParser.parse_file("report.sarif")

# –ò–∑ —Å–ª–æ–≤–∞—Ä—è (–µ—Å–ª–∏ —É–∂–µ –∑–∞–≥—Ä—É–∑–∏–ª–∏ JSON)
import json
with open("report.sarif") as f:
    data = json.load(f)
report = SarifParser.parse_dict(data)
```

### 2. –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏

```python
stats = report.get_statistics()

print(f"–í—Å–µ–≥–æ –Ω–∞—Ö–æ–¥–æ–∫: {stats['total_findings']}")
print(f"–û—à–∏–±–∫–∏: {stats['by_severity']['error']}")
print(f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è: {stats['by_severity']['warning']}")
print(f"–ó–∞–º–µ—Ç–∫–∏: {stats['by_severity']['note']}")

# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø—Ä–∞–≤–∏–ª–∞–º
for rule_id, info in stats['by_rule'].items():
    print(f"{info['name']}: {info['count']} –Ω–∞—Ö–æ–¥–æ–∫")
```

### 3. –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –Ω–∞—Ö–æ–¥–æ–∫

```python
from sarif_parser import SeverityLevel

# –ü–æ —É—Ä–æ–≤–Ω—é —Å–µ—Ä—å–µ–∑–Ω–æ—Å—Ç–∏
critical = [f for f in report.findings if f.level == SeverityLevel.ERROR]
warnings = [f for f in report.findings if f.level == SeverityLevel.WARNING]

# –ü–æ —Ç–∏–ø—É —É—è–∑–≤–∏–º–æ—Å—Ç–∏
sql_injections = [f for f in report.findings if f.rule_id == "sqli"]

# –ü–æ —Ñ–∞–π–ª—É
findings_in_file = [
    f for f in report.findings 
    if any("auth.js" in loc.file_path for loc in f.locations)
]
```

### 4. –†–∞–±–æ—Ç–∞ —Å –ª–æ–∫–∞—Ü–∏—è–º–∏

```python
for finding in report.findings:
    print(f"–£—è–∑–≤–∏–º–æ—Å—Ç—å: {finding.rule_name}")
    
    for location in finding.locations:
        print(f"  –§–∞–π–ª: {location.file_path}")
        if location.start_line:
            print(f"  –°—Ç—Ä–æ–∫–∞: {location.start_line}")
        if location.snippet:
            print(f"  –ö–æ–¥: {location.snippet}")
```

### 5. –≠–∫—Å–ø–æ—Ä—Ç –≤ CSV

```python
import csv

with open("report.csv", 'w', newline='', encoding='utf-8') as f:
    writer = csv.DictWriter(f, fieldnames=['Rule', 'Severity', 'File', 'Line'])
    writer.writeheader()
    
    for finding in report.findings:
        for location in finding.locations:
            writer.writerow({
                'Rule': finding.rule_name,
                'Severity': finding.level.value,
                'File': location.file_path,
                'Line': location.start_line or ''
            })
```

### 6. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è HTML –æ—Ç—á–µ—Ç–∞

```python
from sarif_parser import print_report_summary, print_detailed_findings

# –ö—Ä–∞—Ç–∫–∏–π –æ—Ç—á–µ—Ç
print_report_summary(report)

# –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç (–ø–µ—Ä–≤—ã–µ 20 –Ω–∞—Ö–æ–¥–æ–∫)
print_detailed_findings(report, max_findings=20)
```

## üìö –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö

### SarifReport

–ì–ª–∞–≤–Ω—ã–π –æ–±—ä–µ–∫—Ç –æ—Ç—á–µ—Ç–∞:

```python
class SarifReport:
    tool: ToolInfo              # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–µ
    rules: Dict[str, Rule]      # –°–ª–æ–≤–∞—Ä—å –ø—Ä–∞–≤–∏–ª (–ø–æ ID)
    findings: List[Finding]     # –°–ø–∏—Å–æ–∫ –Ω–∞—Ö–æ–¥–æ–∫
    sarif_version: str          # –í–µ—Ä—Å–∏—è SARIF
```

### ToolInfo

–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è:

```python
class ToolInfo:
    name: str                   # –ù–∞–∑–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞
    version: Optional[str]      # –í–µ—Ä—Å–∏—è
    organization: Optional[str] # –û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è
    information_uri: Optional[str] # URL —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
```

### Rule

–ü—Ä–∞–≤–∏–ª–æ (—Ç–∏–ø —É—è–∑–≤–∏–º–æ—Å—Ç–∏):

```python
class Rule:
    id: str                     # ID –ø—Ä–∞–≤–∏–ª–∞
    name: str                   # –ù–∞–∑–≤–∞–Ω–∏–µ
    description_text: str       # –û–ø–∏—Å–∞–Ω–∏–µ (HTML)
    description_markdown: str   # –û–ø–∏—Å–∞–Ω–∏–µ (Markdown)
    level: SeverityLevel        # –£—Ä–æ–≤–µ–Ω—å —Å–µ—Ä—å–µ–∑–Ω–æ—Å—Ç–∏
    enabled: bool               # –í–∫–ª—é—á–µ–Ω–æ –ª–∏ –ø—Ä–∞–≤–∏–ª–æ
```

### Finding

–ù–∞—Ö–æ–¥–∫–∞ (–∫–æ–Ω–∫—Ä–µ—Ç–Ω–∞—è —É—è–∑–≤–∏–º–æ—Å—Ç—å):

```python
class Finding:
    rule_id: str                # ID –ø—Ä–∞–≤–∏–ª–∞
    rule_name: str              # –ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–∞–≤–∏–ª–∞
    message: str                # –°–æ–æ–±—â–µ–Ω–∏–µ
    level: SeverityLevel        # –£—Ä–æ–≤–µ–Ω—å —Å–µ—Ä—å–µ–∑–Ω–æ—Å—Ç–∏
    locations: List[Location]   # –°–ø–∏—Å–æ–∫ –ª–æ–∫–∞—Ü–∏–π
```

### Location

–õ–æ–∫–∞—Ü–∏—è –Ω–∞—Ö–æ–¥–∫–∏ –≤ –∫–æ–¥–µ:

```python
class Location:
    file_path: str              # –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
    snippet: str                # –§—Ä–∞–≥–º–µ–Ω—Ç –∫–æ–¥–∞
    start_line: int             # –ù–∞—á–∞–ª—å–Ω–∞—è —Å—Ç—Ä–æ–∫–∞
    end_line: int               # –ö–æ–Ω–µ—á–Ω–∞—è —Å—Ç—Ä–æ–∫–∞
    start_column: int           # –ù–∞—á–∞–ª—å–Ω–∞—è –∫–æ–ª–æ–Ω–∫–∞
    end_column: int             # –ö–æ–Ω–µ—á–Ω–∞—è –∫–æ–ª–æ–Ω–∫–∞
```

### SeverityLevel

–£—Ä–æ–≤–Ω–∏ —Å–µ—Ä—å–µ–∑–Ω–æ—Å—Ç–∏:

```python
class SeverityLevel(Enum):
    ERROR = "error"      # üî¥ –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞
    WARNING = "warning"  # üü° –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ
    NOTE = "note"        # üîµ –ó–∞–º–µ—Ç–∫–∞
    NONE = "none"        # ‚ö™ –ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ
```

## üí° –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

### –ü—Ä–∏–º–µ—Ä 1: –ê–Ω–∞–ª–∏–∑ –æ—Ç—á–µ—Ç–∞ PT BlackBox

```python
from sarif_parser import SarifParser, SeverityLevel

# –ó–∞–≥—Ä—É–∂–∞–µ–º –æ—Ç—á–µ—Ç
report = SarifParser.parse_file("blackbox_report.sarif")

# –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ SQL Injection
sqli = [f for f in report.findings if "sql" in f.rule_id.lower()]
print(f"–ù–∞–π–¥–µ–Ω–æ SQL Injection: {len(sqli)}")

# –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ —É—è–∑–≤–∏–º–æ—Å—Ç–∏
critical = [f for f in report.findings if f.level == SeverityLevel.ERROR]
print(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö —É—è–∑–≤–∏–º–æ—Å—Ç–µ–π: {len(critical)}")

# –°–ø–∏—Å–æ–∫ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ —Å —É—è–∑–≤–∏–º–æ—Å—Ç—è–º–∏
vulnerable_files = set()
for finding in report.findings:
    for location in finding.locations:
        vulnerable_files.add(location.file_path)

print(f"–£—è–∑–≤–∏–º—ã—Ö —Ñ–∞–π–ª–æ–≤: {len(vulnerable_files)}")
```

### –ü—Ä–∏–º–µ—Ä 2: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–≤—É—Ö –æ—Ç—á–µ—Ç–æ–≤

```python
from sarif_parser import SarifParser

# –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–≤–∞ –æ—Ç—á–µ—Ç–∞
report_old = SarifParser.parse_file("report_old.sarif")
report_new = SarifParser.parse_file("report_new.sarif")

# –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞—Ö–æ–¥–æ–∫
old_count = len(report_old.findings)
new_count = len(report_new.findings)
diff = new_count - old_count

if diff > 0:
    print(f"‚ùå –ü–æ—è–≤–∏–ª–æ—Å—å {diff} –Ω–æ–≤—ã—Ö –Ω–∞—Ö–æ–¥–æ–∫!")
elif diff < 0:
    print(f"‚úÖ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ {abs(diff)} –Ω–∞—Ö–æ–¥–æ–∫!")
else:
    print("‚ûñ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞—Ö–æ–¥–æ–∫ –Ω–µ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å")

# –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ç–∏–ø—ã —É—è–∑–≤–∏–º–æ—Å—Ç–µ–π
old_rules = set(f.rule_id for f in report_old.findings)
new_rules = set(f.rule_id for f in report_new.findings)

new_types = new_rules - old_rules
if new_types:
    print(f"‚ö†Ô∏è  –ù–æ–≤—ã–µ —Ç–∏–ø—ã —É—è–∑–≤–∏–º–æ—Å—Ç–µ–π: {', '.join(new_types)}")
```

### –ü—Ä–∏–º–µ—Ä 3: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –¥–ª—è CI/CD

```python
from sarif_parser import SarifParser, SeverityLevel
import sys

report = SarifParser.parse_file("report.sarif")

# –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ —É—è–∑–≤–∏–º–æ—Å—Ç–∏
critical_count = sum(
    1 for f in report.findings 
    if f.level == SeverityLevel.ERROR
)

print(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö —É—è–∑–≤–∏–º–æ—Å—Ç–µ–π: {critical_count}")

# –ü—Ä–æ–≤–∞–ª —Å–±–æ—Ä–∫–∏ –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö —É—è–∑–≤–∏–º–æ—Å—Ç–µ–π
if critical_count > 0:
    print("‚ùå –°–±–æ—Ä–∫–∞ –ø—Ä–æ–≤–∞–ª–µ–Ω–∞ –∏–∑-–∑–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö —É—è–∑–≤–∏–º–æ—Å—Ç–µ–π!")
    sys.exit(1)
else:
    print("‚úÖ –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö —É—è–∑–≤–∏–º–æ—Å—Ç–µ–π –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ")
    sys.exit(0)
```

### –ü—Ä–∏–º–µ—Ä 4: –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ —Ñ–∞–π–ª–∞–º

```python
from collections import defaultdict
from sarif_parser import SarifParser

report = SarifParser.parse_file("report.sarif")

# –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –Ω–∞—Ö–æ–¥–∫–∏ –ø–æ —Ñ–∞–π–ª–∞–º
by_file = defaultdict(list)
for finding in report.findings:
    for location in finding.locations:
        by_file[location.file_path].append(finding)

# –¢–æ–ø-10 —Ñ–∞–π–ª–æ–≤ —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —É—è–∑–≤–∏–º–æ—Å—Ç–µ–π
sorted_files = sorted(
    by_file.items(), 
    key=lambda x: len(x[1]), 
    reverse=True
)

print("–¢–æ–ø-10 —É—è–∑–≤–∏–º—ã—Ö —Ñ–∞–π–ª–æ–≤:")
for i, (file_path, findings) in enumerate(sorted_files[:10], 1):
    print(f"{i:2}. [{len(findings):3}] {file_path}")
```

## üõ†Ô∏è –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∏–∑ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏

```bash
# –ë–∞–∑–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑
python sarif_parser.py report.sarif

# –ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö –ø—Ä–∏–º–µ—Ä–æ–≤
python example_usage.py
```

## üìñ –°—Ç–∞–Ω–¥–∞—Ä—Ç SARIF

SARIF (Static Analysis Results Interchange Format) - —ç—Ç–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–ª—è –æ–±–º–µ–Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–¥–∞.

- **–°–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è**: [OASIS SARIF 2.1.0](https://docs.oasis-open.org/sarif/sarif/v2.1.0/sarif-v2.1.0.html)
- **JSON Schema**: http://json.schemastore.org/sarif-2.1.0.json

## üîß –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è

- Python 3.7+
- –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ Python (–Ω–µ—Ç –≤–Ω–µ—à–Ω–∏—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π)

## üìù –õ–∏—Ü–µ–Ω–∑–∏—è

–≠—Ç–æ—Ç –ø–∞—Ä—Å–µ—Ä –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç—Å—è "–∫–∞–∫ –µ—Å—Ç—å" –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –ø—Ä–æ–µ–∫—Ç–∞—Ö –∞–Ω–∞–ª–∏–∑–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏.

## ü§ù –ü–æ–¥–¥–µ—Ä–∂–∫–∞

–ï—Å–ª–∏ —É –≤–∞—Å –≤–æ–∑–Ω–∏–∫–ª–∏ –≤–æ–ø—Ä–æ—Å—ã –∏–ª–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ —É–ª—É—á—à–µ–Ω–∏—é –ø–∞—Ä—Å–µ—Ä–∞:

1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ –≤–∞—à SARIF —Ñ–∞–π–ª —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç—É 2.1.0
2. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç –≤–∞–ª–∏–¥–Ω—ã–π JSON
3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ `example_usage.py`

## üì¶ –§–∞–π–ª—ã –ø—Ä–æ–µ–∫—Ç–∞

- `sarif_parser.py` - –æ—Å–Ω–æ–≤–Ω–æ–π –º–æ–¥—É–ª—å –ø–∞—Ä—Å–µ—Ä–∞
- `example_usage.py` - –ø—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
- `README_SARIF_PARSER.md` - —ç—Ç–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

## üéØ –î–æ—Ä–æ–∂–Ω–∞—è –∫–∞—Ä—Ç–∞

–í–æ–∑–º–æ–∂–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è:

- [ ] –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∑–∞–ø—É—Å–∫–æ–≤ (runs) –≤ –æ–¥–Ω–æ–º —Ñ–∞–π–ª–µ
- [ ] –≠–∫—Å–ø–æ—Ä—Ç –≤ –¥—Ä—É–≥–∏–µ —Ñ–æ—Ä–º–∞—Ç—ã (JSON, XML, Excel)
- [ ] –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö (–≥—Ä–∞—Ñ–∏–∫–∏, –¥–∏–∞–≥—Ä–∞–º–º—ã)
- [ ] –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å —Å–∏—Å—Ç–µ–º–∞–º–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∑–∞–¥–∞—á–∞–º–∏ (Jira, GitLab)
- [ ] CLI —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º–∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
- [ ] –í–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –æ—Ç—á–µ—Ç–æ–≤

## üîç –û—Ç–ª–∞–¥–∫–∞

–ü—Ä–∏ –≤–æ–∑–Ω–∏–∫–Ω–æ–≤–µ–Ω–∏–∏ –ø—Ä–æ–±–ª–µ–º:

```python
from sarif_parser import SarifParser
import json

# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ñ–∞–π–ª–∞
with open("report.sarif") as f:
    data = json.load(f)
    print(f"SARIF –≤–µ—Ä—Å–∏—è: {data.get('version')}")
    print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—É—Å–∫–æ–≤: {len(data.get('runs', []))}")
    
# –ü–∞—Ä—Å–∏–Ω–≥ —Å –æ—Ç–ª–∞–¥–æ—á–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
try:
    report = SarifParser.parse_file("report.sarif")
    print("‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ —É—Å–ø–µ—à–µ–Ω")
except Exception as e:
    print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
    import traceback
    traceback.print_exc()
```

