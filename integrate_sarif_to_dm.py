"""
Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ SARIF Ğ¿Ğ°Ñ€ÑĞµÑ€Ğ° Ñ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ¾Ğ¼ Document Management (DM)

Ğ­Ñ‚Ğ¾Ñ‚ ÑĞºÑ€Ğ¸Ğ¿Ñ‚ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚, ĞºĞ°Ğº Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ SARIF Ğ¿Ğ°Ñ€ÑĞµÑ€
Ğ² ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğ¹ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚ Ğ´Ğ»Ñ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğ°Ğ¼Ğ¸ Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚Ğ¸.
"""

from sarif_parser import SarifParser, SeverityLevel
from datetime import datetime
from pathlib import Path
import json


class SecurityReportManager:
    """ĞœĞµĞ½ĞµĞ´Ğ¶ĞµÑ€ Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğ¾Ğ² Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚Ğ¸ Ğ´Ğ»Ñ DM Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°"""
    
    def __init__(self, reports_dir="security_reports"):
        """
        Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¼ĞµĞ½ĞµĞ´Ğ¶ĞµÑ€Ğ°
        
        Args:
            reports_dir: Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ´Ğ»Ñ Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğ¾Ğ²
        """
        self.reports_dir = Path(reports_dir)
        self.reports_dir.mkdir(exist_ok=True)
    
    def import_sarif_report(self, sarif_file_path, project_name="Unknown"):
        """
        Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ SARIF Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğ° Ğ² ÑĞ¸ÑÑ‚ĞµĞ¼Ñƒ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ
        
        Args:
            sarif_file_path: Ğ¿ÑƒÑ‚ÑŒ Ğº SARIF Ñ„Ğ°Ğ¹Ğ»Ñƒ
            project_name: Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°
            
        Returns:
            dict Ñ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸ĞµĞ¹ Ğ¾Ğ± Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ¼ Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğµ
        """
        print(f"ğŸ“¥ Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ SARIF Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğ°...")
        print(f"   Ğ¤Ğ°Ğ¹Ğ»: {sarif_file_path}")
        print(f"   ĞŸÑ€Ğ¾ĞµĞºÑ‚: {project_name}")
        
        # ĞŸĞ°Ñ€ÑĞ¸Ğ¼ SARIF Ñ„Ğ°Ğ¹Ğ»
        report = SarifParser.parse_file(sarif_file_path)
        stats = report.get_statistics()
        
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ğ¼ĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğ°
        report_metadata = {
            'import_date': datetime.now().isoformat(),
            'project_name': project_name,
            'source_file': str(sarif_file_path),
            'tool': {
                'name': report.tool.name,
                'version': report.tool.version,
                'organization': report.tool.organization
            },
            'statistics': {
                'total_findings': stats['total_findings'],
                'total_rules': stats['total_rules'],
                'by_severity': stats['by_severity'],
                'critical_files': self._get_critical_files(report),
                'top_issues': self._get_top_issues(stats)
            }
        }
        
        # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ¼ĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ
        metadata_file = self.reports_dir / f"report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(report_metadata, f, indent=2, ensure_ascii=False)
        
        print(f"\nâœ… ĞÑ‚Ñ‡ĞµÑ‚ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½!")
        print(f"   ĞœĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ñ‹: {metadata_file}")
        print(f"   Ğ’ÑĞµĞ³Ğ¾ Ğ½Ğ°Ñ…Ğ¾Ğ´Ğ¾Ğº: {stats['total_findings']}")
        print(f"   ĞšÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ…: {stats['by_severity']['error']}")
        
        return report_metadata
    
    def _get_critical_files(self, report):
        """ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ ÑĞ¿Ğ¸ÑĞ¾Ğº ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²"""
        critical_files = set()
        
        for finding in report.findings:
            if finding.level == SeverityLevel.ERROR:
                for location in finding.locations:
                    if location.file_path:
                        critical_files.add(location.file_path)
        
        return list(critical_files)
    
    def _get_top_issues(self, stats, limit=5):
        """ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ñ‚Ğ¾Ğ¿ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼"""
        sorted_rules = sorted(
            stats['by_rule'].items(),
            key=lambda x: x[1]['count'],
            reverse=True
        )
        
        return [
            {
                'rule_id': rule_id,
                'name': info['name'],
                'count': info['count'],
                'severity': info['level']
            }
            for rule_id, info in sorted_rules[:limit]
        ]
    
    def generate_findings_list(self, sarif_file_path, output_format="json"):
        """
        Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ ÑĞ¿Ğ¸ÑĞºĞ° Ğ½Ğ°Ñ…Ğ¾Ğ´Ğ¾Ğº Ğ´Ğ»Ñ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ° Ğ² DM
        
        Args:
            sarif_file_path: Ğ¿ÑƒÑ‚ÑŒ Ğº SARIF Ñ„Ğ°Ğ¹Ğ»Ñƒ
            output_format: Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ° ('json', 'csv')
            
        Returns:
            Ğ¿ÑƒÑ‚ÑŒ Ğº ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ½Ğ¾Ğ¼Ñƒ Ñ„Ğ°Ğ¹Ğ»Ñƒ
        """
        report = SarifParser.parse_file(sarif_file_path)
        
        findings_list = []
        
        for finding in report.findings:
            for location in finding.locations:
                finding_entry = {
                    'id': f"{finding.rule_id}_{hash(location.file_path)}",
                    'title': finding.rule_name or finding.rule_id,
                    'description': finding.message or '',
                    'severity': finding.level.value,
                    'status': 'open',
                    'file_path': location.file_path,
                    'line_number': location.start_line,
                    'code_snippet': location.snippet,
                    'rule_id': finding.rule_id,
                    'detected_date': datetime.now().isoformat()
                }
                findings_list.append(finding_entry)
        
        if output_format == "json":
            output_file = self.reports_dir / f"findings_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(findings_list, f, indent=2, ensure_ascii=False)
        
        elif output_format == "csv":
            import csv
            output_file = self.reports_dir / f"findings_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
            
            if findings_list:
                with open(output_file, 'w', newline='', encoding='utf-8') as f:
                    writer = csv.DictWriter(f, fieldnames=findings_list[0].keys())
                    writer.writeheader()
                    writer.writerows(findings_list)
        
        print(f"âœ… Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº Ğ½Ğ°Ñ…Ğ¾Ğ´Ğ¾Ğº ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½: {output_file}")
        print(f"   Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚: {output_format.upper()}")
        print(f"   Ğ—Ğ°Ğ¿Ğ¸ÑĞµĞ¹: {len(findings_list)}")
        
        return str(output_file)
    
    def create_dashboard_summary(self, sarif_file_path):
        """
        Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ»Ñ Ğ´Ğ°ÑˆĞ±Ğ¾Ñ€Ğ´Ğ° DM
        
        Args:
            sarif_file_path: Ğ¿ÑƒÑ‚ÑŒ Ğº SARIF Ñ„Ğ°Ğ¹Ğ»Ñƒ
            
        Returns:
            dict Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ´Ğ»Ñ Ğ´Ğ°ÑˆĞ±Ğ¾Ñ€Ğ´Ğ°
        """
        report = SarifParser.parse_file(sarif_file_path)
        stats = report.get_statistics()
        
        # Ğ¤Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒĞµĞ¼ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ»Ñ Ğ´Ğ°ÑˆĞ±Ğ¾Ñ€Ğ´Ğ°
        dashboard_data = {
            'scan_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'tool_name': report.tool.name,
            'summary': {
                'total': stats['total_findings'],
                'critical': stats['by_severity']['error'],
                'high': stats['by_severity']['warning'],
                'medium': stats['by_severity']['note'],
                'low': 0
            },
            'charts': {
                'severity_distribution': [
                    {'name': 'ĞšÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ', 'value': stats['by_severity']['error']},
                    {'name': 'ĞŸÑ€ĞµĞ´ÑƒĞ¿Ñ€ĞµĞ¶Ğ´ĞµĞ½Ğ¸Ñ', 'value': stats['by_severity']['warning']},
                    {'name': 'Ğ—Ğ°Ğ¼ĞµÑ‚ĞºĞ¸', 'value': stats['by_severity']['note']}
                ],
                'top_vulnerabilities': stats['by_rule']
            },
            'recommendations': self._generate_recommendations(report)
        }
        
        # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ´Ğ»Ñ Ğ´Ğ°ÑˆĞ±Ğ¾Ñ€Ğ´Ğ°
        output_file = self.reports_dir / "dashboard_data.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(dashboard_data, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… Ğ”Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ»Ñ Ğ´Ğ°ÑˆĞ±Ğ¾Ñ€Ğ´Ğ° ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ñ‹: {output_file}")
        
        return dashboard_data
    
    def _generate_recommendations(self, report):
        """Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¹ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ½Ğ°Ñ…Ğ¾Ğ´Ğ¾Ğº"""
        recommendations = []
        
        # ĞŸĞ¾Ğ´ÑÑ‡ĞµÑ‚ ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ…
        critical_count = sum(
            1 for f in report.findings 
            if f.level == SeverityLevel.ERROR
        )
        
        if critical_count > 0:
            recommendations.append({
                'priority': 'high',
                'text': f'ĞĞ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¾ {critical_count} ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… ÑƒÑĞ·Ğ²Ğ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹. Ğ¢Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ Ğ½ĞµĞ¼ĞµĞ´Ğ»ĞµĞ½Ğ½Ğ¾Ğµ Ğ¸ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ!'
            })
        
        # ĞŸĞ¾Ğ´ÑÑ‡ĞµÑ‚ SQL Injection
        sqli_count = sum(
            1 for f in report.findings 
            if 'sql' in f.rule_id.lower()
        )
        
        if sqli_count > 0:
            recommendations.append({
                'priority': 'high',
                'text': f'ĞĞ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¾ {sqli_count} ÑƒÑĞ·Ğ²Ğ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹ SQL Injection. Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹Ñ‚Ğµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑ‹.'
            })
        
        # ĞŸĞ¾Ğ´ÑÑ‡ĞµÑ‚ XSS
        xss_count = sum(
            1 for f in report.findings 
            if 'xss' in f.rule_id.lower()
        )
        
        if xss_count > 0:
            recommendations.append({
                'priority': 'medium',
                'text': f'ĞĞ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¾ {xss_count} ÑƒÑĞ·Ğ²Ğ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹ XSS. Ğ­ĞºÑ€Ğ°Ğ½Ğ¸Ñ€ÑƒĞ¹Ñ‚Ğµ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒÑĞºĞ¸Ğ¹ Ğ²Ğ²Ğ¾Ğ´.'
            })
        
        return recommendations


def demo_integration():
    """Ğ”ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ğ¸ Ñ DM Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ¾Ğ¼"""
    
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                              â•‘
â•‘             ğŸ”— Ğ˜ĞĞ¢Ğ•Ğ“Ğ ĞĞ¦Ğ˜Ğ¯ SARIF ĞŸĞĞ Ğ¡Ğ•Ğ Ğ Ğ¡ ĞŸĞ ĞĞ•ĞšĞ¢ĞĞœ DM                        â•‘
â•‘                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")
    
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ğ¼ĞµĞ½ĞµĞ´Ğ¶ĞµÑ€
    manager = SecurityReportManager(reports_dir="security_reports")
    
    print("\nğŸ“ Ğ”Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ´Ğ»Ñ Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğ¾Ğ² ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ°: security_reports/\n")
    
    # Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ´Ğ»Ñ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
    test_files = [
        (r"C:\Users\ssinyakov\Downloads\bbs2_ru.sarif", "DM Project - BlackBox Scan 2"),
        (r"C:\Users\ssinyakov\Downloads\bbs1_ru.sarif", "DM Project - BlackBox Scan 1"),
    ]
    
    for sarif_file, project_name in test_files:
        if not Path(sarif_file).exists():
            print(f"â­  ĞŸÑ€Ğ¾Ğ¿ÑƒÑĞº: {sarif_file} Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½\n")
            continue
        
        print(f"\n{'='*80}")
        print(f"ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°: {project_name}")
        print(f"{'='*80}\n")
        
        try:
            # 1. Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğ°
            metadata = manager.import_sarif_report(sarif_file, project_name)
            
            print("\n" + "-"*80)
            
            # 2. Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ ÑĞ¿Ğ¸ÑĞºĞ° Ğ½Ğ°Ñ…Ğ¾Ğ´Ğ¾Ğº
            print("\nğŸ“ Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ ÑĞ¿Ğ¸ÑĞºĞ° Ğ½Ğ°Ñ…Ğ¾Ğ´Ğ¾Ğº...")
            findings_file = manager.generate_findings_list(sarif_file, output_format="json")
            
            print("\n" + "-"*80)
            
            # 3. Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ´Ğ°ÑˆĞ±Ğ¾Ñ€Ğ´Ğ°
            print("\nğŸ“Š Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ´Ğ°ÑˆĞ±Ğ¾Ñ€Ğ´Ğ°...")
            dashboard_data = manager.create_dashboard_summary(sarif_file)
            
            # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸
            if dashboard_data['recommendations']:
                print("\nğŸ’¡ Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸:")
                for rec in dashboard_data['recommendations']:
                    priority_icon = {
                        'high': 'ğŸ”´',
                        'medium': 'ğŸŸ¡',
                        'low': 'ğŸ”µ'
                    }.get(rec['priority'], 'âšª')
                    print(f"   {priority_icon} {rec['text']}")
            
            input("\nâ¸  ĞĞ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ Enter Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½Ğ¸Ñ...")
            
        except Exception as e:
            print(f"\nâŒ ĞÑˆĞ¸Ğ±ĞºĞ°: {e}")
            import traceback
            traceback.print_exc()
    
    print(f"\n{'='*80}")
    print("âœ… Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ°!")
    print(f"{'='*80}\n")
    
    print("ğŸ“‚ Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ñ„Ğ°Ğ¹Ğ»Ñ‹:")
    if Path("security_reports").exists():
        for file in Path("security_reports").glob("*"):
            print(f"   - {file.name}")
    
    print("""
ğŸ¯ Ğ¡Ğ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğµ ÑˆĞ°Ğ³Ğ¸:

1. Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ² Ğ±Ğ°Ğ·Ñƒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… DM Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°
2. Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ UI Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ½Ğ°Ñ…Ğ¾Ğ´Ğ¾Ğº
3. ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¸Ñ‚ÑŒ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ ÑĞºĞ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
4. Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ ÑĞ¸ÑÑ‚ĞµĞ¼Ñƒ Ñ‚Ñ€ĞµĞºĞ¸Ğ½Ğ³Ğ° Ğ¸ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğ¹

ğŸ“š Ğ¡Ğ¼. ARCHITECTURE.md Ğ´Ğ»Ñ Ğ´ĞµÑ‚Ğ°Ğ»ĞµĞ¹ Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ğ¸ Ğ² DM Ğ¿Ñ€Ğ¾ĞµĞºÑ‚
""")


if __name__ == "__main__":
    demo_integration()

